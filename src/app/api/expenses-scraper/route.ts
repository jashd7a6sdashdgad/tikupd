import { NextRequest, NextResponse } from 'next/server';
import { validateApiToken, hasPermission } from '@/lib/api/auth/tokenValidation';
import jwt from 'jsonwebtoken';

// Web scraper to get expenses from the website
export async function GET(request: NextRequest) {
  let validToken: any = null;
  let authType = 'unknown';
  
  try {
    // Get the Authorization header
    const authHeader = request.headers.get('authorization');
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return NextResponse.json(
        { error: 'Authorization header required. Use format: Bearer YOUR_TOKEN' },
        { status: 401 }
      );
    }

    const token = authHeader.replace('Bearer ', '');

    // Try to validate as website JWT first
    try {
      const decoded = jwt.verify(token, process.env.JWT_SECRET || 'punz') as any;
      
      validToken = {
        id: decoded.userId || '1',
        name: decoded.username || 'website-user',
        permissions: ['*'],
        email: decoded.email,
        type: 'website-jwt'
      };
      authType = 'website-jwt';
      
    } catch (jwtError: any) {
      // Try to validate as API token
      const validation = await validateApiToken(authHeader);
      
      if (!validation.isValid) {
        return NextResponse.json(
          { 
            success: false,
            error: 'Authentication failed',
            message: 'Invalid token.'
          },
          { status: 401 }
        );
      }
      
      validToken = validation.token!;
      authType = 'api-token';
    }

    console.log('üåê Scraping expenses data from website...');

    // Fetch the expenses page with authentication
    const response = await fetch('https://www.mahboobagents.fun/expenses', {
      method: 'GET',
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.5',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Pragma': 'no-cache',
        'Cache-Control': 'no-cache'
      }
    });

    if (!response.ok) {
      throw new Error(`Failed to fetch expenses page: ${response.status} ${response.statusText}`);
    }

    const html = await response.text();
    console.log('‚úÖ Fetched HTML from expenses page, size:', html.length, 'bytes');

    // Extract expenses data from HTML - look for common patterns
    const expenses = extractExpensesFromHtml(html);

    console.log(`üìä Extracted ${expenses.length} expenses from website`);

    // Calculate analytics
    const total = expenses.reduce((sum: number, exp: any) => sum + (exp.amount || 0), 0);
    const categoryTotals = expenses.reduce((acc: any, exp: any) => {
      acc[exp.category] = (acc[exp.category] || 0) + (exp.amount || 0);
      return acc;
    }, {});
    
    const analyticsData = {
      total,
      count: expenses.length,
      categoryTotals,
      averageExpense: expenses.length > 0 ? total / expenses.length : 0
    };

    return NextResponse.json({
      success: true,
      message: 'Expenses retrieved successfully from website scraping',
      data: {
        expenses: expenses,
        total: expenses.length,
        analytics: analyticsData,
        storageType: 'Website Scraping (Real Data)',
        scrapedFrom: 'https://www.mahboobagents.fun/expenses',
        token: {
          name: validToken ? validToken.name : 'Unknown',
          permissions: validToken ? validToken.permissions : [],
          type: authType,
          createdAt: validToken ? validToken.createdAt : new Date().toISOString()
        }
      }
    });

  } catch (error: any) {
    console.error('Expenses scraping error:', error);
    
    // Return fallback data if scraping fails
    const fallbackExpenses = [
      {
        id: "exp_fallback_001",
        amount: 125.50,
        category: "groceries",
        description: "Weekly grocery shopping (scraped from website)",
        date: "2025-08-12",
        merchant: "Lulu Hypermarket",
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
        source: "fallback"
      },
      {
        id: "exp_fallback_002", 
        amount: 45.75,
        category: "fuel",
        description: "Gas station fill-up (scraped from website)",
        date: "2025-08-11",
        merchant: "ADNOC Station", 
        createdAt: new Date().toISOString(),
        updatedAt: new Date().toISOString(),
        source: "fallback"
      }
    ];

    const total = fallbackExpenses.reduce((sum: number, exp: any) => sum + (exp.amount || 0), 0);
    const categoryTotals = fallbackExpenses.reduce((acc: any, exp: any) => {
      acc[exp.category] = (acc[exp.category] || 0) + (exp.amount || 0);
      return acc;
    }, {});

    return NextResponse.json({
      success: true,
      message: 'Expenses data (fallback - scraping failed)',
      data: {
        expenses: fallbackExpenses,
        total: fallbackExpenses.length,
        analytics: {
          total,
          count: fallbackExpenses.length,
          categoryTotals,
          averageExpense: fallbackExpenses.length > 0 ? total / fallbackExpenses.length : 0
        },
        storageType: 'Fallback Data (Scraping Failed)',
        error: error.message
      }
    });
  }
}

// Function to extract expenses data from HTML
function extractExpensesFromHtml(html: string): any[] {
  const expenses: any[] = [];
  
  try {
    // Look for various patterns in the HTML that might contain expense data
    
    // Pattern 1: Look for JSON data in script tags
    const scriptMatches = html.match(/<script[^>]*>[\s\S]*?expenses[\s\S]*?<\/script>/gi);
    if (scriptMatches) {
      for (const script of scriptMatches) {
        const jsonMatch = script.match(/expenses["\']?\s*:\s*(\[[\s\S]*?\])/);
        if (jsonMatch) {
          try {
            const expensesData = JSON.parse(jsonMatch[1]);
            expenses.push(...expensesData.map((exp: any, index: number) => ({
              id: exp.id || `scraped_${index + 1}`,
              amount: parseFloat(exp.amount) || parseFloat(exp.debitAmount) || 0,
              category: exp.category || 'general',
              description: exp.description || exp.from || 'Scraped expense',
              date: exp.date || new Date().toISOString().split('T')[0],
              merchant: exp.merchant || exp.from || 'Unknown',
              createdAt: new Date().toISOString(),
              updatedAt: new Date().toISOString(),
              source: 'website_json'
            })));
          } catch (parseError) {
            console.log('Failed to parse JSON from script:', parseError);
          }
        }
      }
    }

    // Pattern 2: Look for table data
    const tableMatches = html.match(/<table[\s\S]*?<\/table>/gi);
    if (tableMatches && expenses.length === 0) {
      for (const table of tableMatches) {
        const rows = table.match(/<tr[\s\S]*?<\/tr>/gi);
        if (rows && rows.length > 1) {
          for (let i = 1; i < rows.length; i++) { // Skip header row
            const cells = rows[i].match(/<td[^>]*>([\s\S]*?)<\/td>/gi);
            if (cells && cells.length >= 3) {
              const cellData = cells.map(cell => cell.replace(/<[^>]*>/g, '').trim());
              if (cellData.length >= 3 && cellData[1] && parseFloat(cellData[1])) {
                expenses.push({
                  id: `table_scraped_${i}`,
                  amount: parseFloat(cellData[1]) || 0,
                  category: cellData[2] || 'general',
                  description: cellData[0] || 'Table expense',
                  date: cellData[3] || new Date().toISOString().split('T')[0],
                  merchant: cellData[4] || 'Unknown',
                  createdAt: new Date().toISOString(),
                  updatedAt: new Date().toISOString(),
                  source: 'website_table'
                });
              }
            }
          }
        }
      }
    }

    // Pattern 3: Look for div/card structures with expense data
    if (expenses.length === 0) {
      const cardMatches = html.match(/<div[^>]*class[^>]*card[^>]*>[\s\S]*?<\/div>/gi);
      if (cardMatches) {
        cardMatches.forEach((card, index) => {
          const amountMatch = card.match(/\$?(\d+\.?\d*)/);
          const categoryMatch = card.match(/category["\']?\s*:\s*["\']([^"']+)/i);
          const descMatch = card.match(/description["\']?\s*:\s*["\']([^"']+)/i);
          
          if (amountMatch) {
            expenses.push({
              id: `card_scraped_${index + 1}`,
              amount: parseFloat(amountMatch[1]) || 0,
              category: categoryMatch ? categoryMatch[1] : 'general',
              description: descMatch ? descMatch[1] : 'Card expense',
              date: new Date().toISOString().split('T')[0],
              merchant: 'Website',
              createdAt: new Date().toISOString(),
              updatedAt: new Date().toISOString(),
              source: 'website_card'
            });
          }
        });
      }
    }

    console.log(`üîç Extracted ${expenses.length} expenses using HTML parsing`);
    
  } catch (parseError) {
    console.error('HTML parsing error:', parseError);
  }

  return expenses;
}